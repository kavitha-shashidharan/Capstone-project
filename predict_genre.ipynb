{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "%matplotlib inline\n",
    "import os\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import pathlib\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_df = pd.read_csv('song_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>chroma_stft</th>\n",
       "      <th>rmse</th>\n",
       "      <th>spectral_centroid</th>\n",
       "      <th>spectral_bandwidth</th>\n",
       "      <th>rolloff</th>\n",
       "      <th>zero_crossing_rate</th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>mfcc2</th>\n",
       "      <th>mfcc3</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc12</th>\n",
       "      <th>mfcc13</th>\n",
       "      <th>mfcc14</th>\n",
       "      <th>mfcc15</th>\n",
       "      <th>mfcc16</th>\n",
       "      <th>mfcc17</th>\n",
       "      <th>mfcc18</th>\n",
       "      <th>mfcc19</th>\n",
       "      <th>mfcc20</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>happy_015.mp3</td>\n",
       "      <td>0.457246</td>\n",
       "      <td>0.022467</td>\n",
       "      <td>2313.413622</td>\n",
       "      <td>2626.782970</td>\n",
       "      <td>4124.601950</td>\n",
       "      <td>0.056585</td>\n",
       "      <td>-537.234192</td>\n",
       "      <td>91.823860</td>\n",
       "      <td>35.459835</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.303244</td>\n",
       "      <td>-2.529682</td>\n",
       "      <td>-0.756528</td>\n",
       "      <td>-0.102221</td>\n",
       "      <td>-0.657489</td>\n",
       "      <td>-0.360597</td>\n",
       "      <td>-0.160689</td>\n",
       "      <td>-1.208762</td>\n",
       "      <td>-1.592072</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>happy_001.mp3</td>\n",
       "      <td>0.274254</td>\n",
       "      <td>0.058960</td>\n",
       "      <td>717.333558</td>\n",
       "      <td>713.542579</td>\n",
       "      <td>1129.112190</td>\n",
       "      <td>0.026445</td>\n",
       "      <td>-389.157745</td>\n",
       "      <td>218.432053</td>\n",
       "      <td>32.675011</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.250138</td>\n",
       "      <td>-12.127299</td>\n",
       "      <td>-7.517781</td>\n",
       "      <td>-2.840759</td>\n",
       "      <td>0.056820</td>\n",
       "      <td>4.290653</td>\n",
       "      <td>5.128882</td>\n",
       "      <td>2.677651</td>\n",
       "      <td>0.546200</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>happy_029.mp3</td>\n",
       "      <td>0.393490</td>\n",
       "      <td>0.063921</td>\n",
       "      <td>516.544569</td>\n",
       "      <td>647.894549</td>\n",
       "      <td>770.933663</td>\n",
       "      <td>0.017521</td>\n",
       "      <td>-404.102905</td>\n",
       "      <td>206.850693</td>\n",
       "      <td>68.775932</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.706476</td>\n",
       "      <td>-8.817365</td>\n",
       "      <td>-1.754093</td>\n",
       "      <td>4.350704</td>\n",
       "      <td>2.414201</td>\n",
       "      <td>-2.776739</td>\n",
       "      <td>-2.774598</td>\n",
       "      <td>-0.309426</td>\n",
       "      <td>-2.359100</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>happy_217.mp3</td>\n",
       "      <td>0.360551</td>\n",
       "      <td>0.081740</td>\n",
       "      <td>637.271723</td>\n",
       "      <td>614.921151</td>\n",
       "      <td>1020.346393</td>\n",
       "      <td>0.027209</td>\n",
       "      <td>-369.361420</td>\n",
       "      <td>211.137619</td>\n",
       "      <td>57.493961</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.958784</td>\n",
       "      <td>-11.036363</td>\n",
       "      <td>-7.450860</td>\n",
       "      <td>0.486627</td>\n",
       "      <td>2.838610</td>\n",
       "      <td>-0.458699</td>\n",
       "      <td>-1.893717</td>\n",
       "      <td>-0.376333</td>\n",
       "      <td>-0.483401</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>happy_203.mp3</td>\n",
       "      <td>0.338282</td>\n",
       "      <td>0.110650</td>\n",
       "      <td>640.259406</td>\n",
       "      <td>636.496897</td>\n",
       "      <td>1122.076094</td>\n",
       "      <td>0.024941</td>\n",
       "      <td>-322.983856</td>\n",
       "      <td>259.454285</td>\n",
       "      <td>33.289051</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.428184</td>\n",
       "      <td>-3.662958</td>\n",
       "      <td>-0.929638</td>\n",
       "      <td>1.900791</td>\n",
       "      <td>-0.808726</td>\n",
       "      <td>-3.739435</td>\n",
       "      <td>-3.212300</td>\n",
       "      <td>-2.063034</td>\n",
       "      <td>-1.726896</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        filename  chroma_stft      rmse  spectral_centroid  \\\n",
       "0  happy_015.mp3     0.457246  0.022467        2313.413622   \n",
       "1  happy_001.mp3     0.274254  0.058960         717.333558   \n",
       "2  happy_029.mp3     0.393490  0.063921         516.544569   \n",
       "3  happy_217.mp3     0.360551  0.081740         637.271723   \n",
       "4  happy_203.mp3     0.338282  0.110650         640.259406   \n",
       "\n",
       "   spectral_bandwidth      rolloff  zero_crossing_rate       mfcc1  \\\n",
       "0         2626.782970  4124.601950            0.056585 -537.234192   \n",
       "1          713.542579  1129.112190            0.026445 -389.157745   \n",
       "2          647.894549   770.933663            0.017521 -404.102905   \n",
       "3          614.921151  1020.346393            0.027209 -369.361420   \n",
       "4          636.496897  1122.076094            0.024941 -322.983856   \n",
       "\n",
       "        mfcc2      mfcc3  ...     mfcc12     mfcc13    mfcc14    mfcc15  \\\n",
       "0   91.823860  35.459835  ...  -2.303244  -2.529682 -0.756528 -0.102221   \n",
       "1  218.432053  32.675011  ...  -7.250138 -12.127299 -7.517781 -2.840759   \n",
       "2  206.850693  68.775932  ... -10.706476  -8.817365 -1.754093  4.350704   \n",
       "3  211.137619  57.493961  ...  -5.958784 -11.036363 -7.450860  0.486627   \n",
       "4  259.454285  33.289051  ...  -1.428184  -3.662958 -0.929638  1.900791   \n",
       "\n",
       "     mfcc16    mfcc17    mfcc18    mfcc19    mfcc20  label  \n",
       "0 -0.657489 -0.360597 -0.160689 -1.208762 -1.592072  happy  \n",
       "1  0.056820  4.290653  5.128882  2.677651  0.546200  happy  \n",
       "2  2.414201 -2.776739 -2.774598 -0.309426 -2.359100  happy  \n",
       "3  2.838610 -0.458699 -1.893717 -0.376333 -0.483401  happy  \n",
       "4 -0.808726 -3.739435 -3.212300 -2.063034 -1.726896  happy  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_list = songs_df.iloc[:, -1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chroma_stft</th>\n",
       "      <th>rmse</th>\n",
       "      <th>spectral_centroid</th>\n",
       "      <th>spectral_bandwidth</th>\n",
       "      <th>rolloff</th>\n",
       "      <th>zero_crossing_rate</th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>mfcc2</th>\n",
       "      <th>mfcc3</th>\n",
       "      <th>mfcc4</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc11</th>\n",
       "      <th>mfcc12</th>\n",
       "      <th>mfcc13</th>\n",
       "      <th>mfcc14</th>\n",
       "      <th>mfcc15</th>\n",
       "      <th>mfcc16</th>\n",
       "      <th>mfcc17</th>\n",
       "      <th>mfcc18</th>\n",
       "      <th>mfcc19</th>\n",
       "      <th>mfcc20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.457246</td>\n",
       "      <td>0.022467</td>\n",
       "      <td>2313.413622</td>\n",
       "      <td>2626.782970</td>\n",
       "      <td>4124.601950</td>\n",
       "      <td>0.056585</td>\n",
       "      <td>-537.234192</td>\n",
       "      <td>91.823860</td>\n",
       "      <td>35.459835</td>\n",
       "      <td>8.019248</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.754915</td>\n",
       "      <td>-2.303244</td>\n",
       "      <td>-2.529682</td>\n",
       "      <td>-0.756528</td>\n",
       "      <td>-0.102221</td>\n",
       "      <td>-0.657489</td>\n",
       "      <td>-0.360597</td>\n",
       "      <td>-0.160689</td>\n",
       "      <td>-1.208762</td>\n",
       "      <td>-1.592072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.274254</td>\n",
       "      <td>0.058960</td>\n",
       "      <td>717.333558</td>\n",
       "      <td>713.542579</td>\n",
       "      <td>1129.112190</td>\n",
       "      <td>0.026445</td>\n",
       "      <td>-389.157745</td>\n",
       "      <td>218.432053</td>\n",
       "      <td>32.675011</td>\n",
       "      <td>-19.545815</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.030162</td>\n",
       "      <td>-7.250138</td>\n",
       "      <td>-12.127299</td>\n",
       "      <td>-7.517781</td>\n",
       "      <td>-2.840759</td>\n",
       "      <td>0.056820</td>\n",
       "      <td>4.290653</td>\n",
       "      <td>5.128882</td>\n",
       "      <td>2.677651</td>\n",
       "      <td>0.546200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.393490</td>\n",
       "      <td>0.063921</td>\n",
       "      <td>516.544569</td>\n",
       "      <td>647.894549</td>\n",
       "      <td>770.933663</td>\n",
       "      <td>0.017521</td>\n",
       "      <td>-404.102905</td>\n",
       "      <td>206.850693</td>\n",
       "      <td>68.775932</td>\n",
       "      <td>-2.267009</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.267504</td>\n",
       "      <td>-10.706476</td>\n",
       "      <td>-8.817365</td>\n",
       "      <td>-1.754093</td>\n",
       "      <td>4.350704</td>\n",
       "      <td>2.414201</td>\n",
       "      <td>-2.776739</td>\n",
       "      <td>-2.774598</td>\n",
       "      <td>-0.309426</td>\n",
       "      <td>-2.359100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.360551</td>\n",
       "      <td>0.081740</td>\n",
       "      <td>637.271723</td>\n",
       "      <td>614.921151</td>\n",
       "      <td>1020.346393</td>\n",
       "      <td>0.027209</td>\n",
       "      <td>-369.361420</td>\n",
       "      <td>211.137619</td>\n",
       "      <td>57.493961</td>\n",
       "      <td>-11.652444</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.013260</td>\n",
       "      <td>-5.958784</td>\n",
       "      <td>-11.036363</td>\n",
       "      <td>-7.450860</td>\n",
       "      <td>0.486627</td>\n",
       "      <td>2.838610</td>\n",
       "      <td>-0.458699</td>\n",
       "      <td>-1.893717</td>\n",
       "      <td>-0.376333</td>\n",
       "      <td>-0.483401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.338282</td>\n",
       "      <td>0.110650</td>\n",
       "      <td>640.259406</td>\n",
       "      <td>636.496897</td>\n",
       "      <td>1122.076094</td>\n",
       "      <td>0.024941</td>\n",
       "      <td>-322.983856</td>\n",
       "      <td>259.454285</td>\n",
       "      <td>33.289051</td>\n",
       "      <td>-27.118906</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.669189</td>\n",
       "      <td>-1.428184</td>\n",
       "      <td>-3.662958</td>\n",
       "      <td>-0.929638</td>\n",
       "      <td>1.900791</td>\n",
       "      <td>-0.808726</td>\n",
       "      <td>-3.739435</td>\n",
       "      <td>-3.212300</td>\n",
       "      <td>-2.063034</td>\n",
       "      <td>-1.726896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   chroma_stft      rmse  spectral_centroid  spectral_bandwidth      rolloff  \\\n",
       "0     0.457246  0.022467        2313.413622         2626.782970  4124.601950   \n",
       "1     0.274254  0.058960         717.333558          713.542579  1129.112190   \n",
       "2     0.393490  0.063921         516.544569          647.894549   770.933663   \n",
       "3     0.360551  0.081740         637.271723          614.921151  1020.346393   \n",
       "4     0.338282  0.110650         640.259406          636.496897  1122.076094   \n",
       "\n",
       "   zero_crossing_rate       mfcc1       mfcc2      mfcc3      mfcc4  ...  \\\n",
       "0            0.056585 -537.234192   91.823860  35.459835   8.019248  ...   \n",
       "1            0.026445 -389.157745  218.432053  32.675011 -19.545815  ...   \n",
       "2            0.017521 -404.102905  206.850693  68.775932  -2.267009  ...   \n",
       "3            0.027209 -369.361420  211.137619  57.493961 -11.652444  ...   \n",
       "4            0.024941 -322.983856  259.454285  33.289051 -27.118906  ...   \n",
       "\n",
       "      mfcc11     mfcc12     mfcc13    mfcc14    mfcc15    mfcc16    mfcc17  \\\n",
       "0  -0.754915  -2.303244  -2.529682 -0.756528 -0.102221 -0.657489 -0.360597   \n",
       "1  -2.030162  -7.250138 -12.127299 -7.517781 -2.840759  0.056820  4.290653   \n",
       "2 -10.267504 -10.706476  -8.817365 -1.754093  4.350704  2.414201 -2.776739   \n",
       "3  -1.013260  -5.958784 -11.036363 -7.450860  0.486627  2.838610 -0.458699   \n",
       "4  -1.669189  -1.428184  -3.662958 -0.929638  1.900791 -0.808726 -3.739435   \n",
       "\n",
       "     mfcc18    mfcc19    mfcc20  \n",
       "0 -0.160689 -1.208762 -1.592072  \n",
       "1  5.128882  2.677651  0.546200  \n",
       "2 -2.774598 -0.309426 -2.359100  \n",
       "3 -1.893717 -0.376333 -0.483401  \n",
       "4 -3.212300 -2.063034 -1.726896  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = songs_df.iloc[:, :-1].drop(['filename'], axis = 1)\n",
    "y = genre_list\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = DataFrameMapper([(['chroma_stft'], [StandardScaler()]),\n",
    "(['rmse'], [StandardScaler()]),\n",
    "(['spectral_centroid'], [StandardScaler()]),\n",
    "(['spectral_bandwidth'], [StandardScaler()]),\n",
    "(['rolloff'], [StandardScaler()]),\n",
    "(['zero_crossing_rate'], [StandardScaler()]),\n",
    "(['mfcc1'], [StandardScaler()]),\n",
    "(['mfcc2'], [StandardScaler()]),\n",
    "(['mfcc3'], [StandardScaler()]),\n",
    "(['mfcc4'], [StandardScaler()]),\n",
    "(['mfcc5'], [StandardScaler()]),\n",
    "(['mfcc6'], [StandardScaler()]),\n",
    "(['mfcc7'], [StandardScaler()]),\n",
    "(['mfcc8'], [StandardScaler()]),\n",
    "(['mfcc9'], [StandardScaler()]),\n",
    "(['mfcc10'], [StandardScaler()]),\n",
    "(['mfcc11'], [StandardScaler()]),\n",
    "(['mfcc12'], [StandardScaler()]),\n",
    "(['mfcc13'], [StandardScaler()]),\n",
    "(['mfcc14'], [StandardScaler()]),\n",
    "(['mfcc15'], [StandardScaler()]),\n",
    "(['mfcc16'], [StandardScaler()]),\n",
    "(['mfcc17'], [StandardScaler()]),\n",
    "(['mfcc18'], [StandardScaler()]),\n",
    "(['mfcc19'], [StandardScaler()]),\n",
    "(['mfcc20'], [StandardScaler()])],input_df = True,df_out=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = mapper.fit_transform(X_train)\n",
    "X_test = mapper.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9381443298969072"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(penalty = 'l2', C = 1.0, solver='saga')\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = (logreg.predict(X_test)).round()\n",
    "logreg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(mapper, logreg)\n",
    "pipe.fit(X_train, y_train)\n",
    "pipe.predict(X_test).round()\n",
    "pickle.dump(pipe, open('pipe.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "       1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', kernel_initializer = 'he_normal', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(20, kernel_initializer = 'he_normal', activation='relu'))\n",
    "model.add(Dense(15, kernel_initializer = 'he_normal', activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 262 samples, validate on 130 samples\n",
      "Epoch 1/100\n",
      "262/262 [==============================] - 0s 858us/step - loss: 0.9659 - accuracy: 0.5534 - val_loss: 0.8012 - val_accuracy: 0.5615\n",
      "Epoch 2/100\n",
      "262/262 [==============================] - 0s 202us/step - loss: 0.6575 - accuracy: 0.6718 - val_loss: 0.5961 - val_accuracy: 0.7077\n",
      "Epoch 3/100\n",
      "262/262 [==============================] - 0s 159us/step - loss: 0.5635 - accuracy: 0.7405 - val_loss: 0.5137 - val_accuracy: 0.7692\n",
      "Epoch 4/100\n",
      "262/262 [==============================] - 0s 146us/step - loss: 0.4902 - accuracy: 0.7748 - val_loss: 0.4769 - val_accuracy: 0.8000\n",
      "Epoch 5/100\n",
      "262/262 [==============================] - 0s 137us/step - loss: 0.4317 - accuracy: 0.8168 - val_loss: 0.4329 - val_accuracy: 0.8308\n",
      "Epoch 6/100\n",
      "262/262 [==============================] - 0s 136us/step - loss: 0.3801 - accuracy: 0.8588 - val_loss: 0.4043 - val_accuracy: 0.8538\n",
      "Epoch 7/100\n",
      "262/262 [==============================] - 0s 136us/step - loss: 0.3349 - accuracy: 0.8855 - val_loss: 0.3891 - val_accuracy: 0.8692\n",
      "Epoch 8/100\n",
      "262/262 [==============================] - 0s 135us/step - loss: 0.2990 - accuracy: 0.8893 - val_loss: 0.3632 - val_accuracy: 0.8846\n",
      "Epoch 9/100\n",
      "262/262 [==============================] - 0s 125us/step - loss: 0.2684 - accuracy: 0.9046 - val_loss: 0.3565 - val_accuracy: 0.8923\n",
      "Epoch 10/100\n",
      "262/262 [==============================] - 0s 132us/step - loss: 0.2376 - accuracy: 0.9084 - val_loss: 0.3355 - val_accuracy: 0.8846\n",
      "Epoch 11/100\n",
      "262/262 [==============================] - 0s 122us/step - loss: 0.2115 - accuracy: 0.9160 - val_loss: 0.3303 - val_accuracy: 0.8769\n",
      "Epoch 12/100\n",
      "262/262 [==============================] - 0s 138us/step - loss: 0.1895 - accuracy: 0.9198 - val_loss: 0.3253 - val_accuracy: 0.8692\n",
      "Epoch 13/100\n",
      "262/262 [==============================] - 0s 138us/step - loss: 0.1683 - accuracy: 0.9466 - val_loss: 0.3181 - val_accuracy: 0.8692\n",
      "Epoch 14/100\n",
      "262/262 [==============================] - 0s 143us/step - loss: 0.1523 - accuracy: 0.9504 - val_loss: 0.3100 - val_accuracy: 0.8692\n",
      "Epoch 15/100\n",
      "262/262 [==============================] - 0s 129us/step - loss: 0.1349 - accuracy: 0.9656 - val_loss: 0.3060 - val_accuracy: 0.8692\n",
      "Epoch 16/100\n",
      "262/262 [==============================] - 0s 131us/step - loss: 0.1202 - accuracy: 0.9656 - val_loss: 0.3052 - val_accuracy: 0.8923\n",
      "Epoch 17/100\n",
      "262/262 [==============================] - 0s 136us/step - loss: 0.1067 - accuracy: 0.9733 - val_loss: 0.3108 - val_accuracy: 0.8923\n",
      "Epoch 18/100\n",
      "262/262 [==============================] - 0s 140us/step - loss: 0.0958 - accuracy: 0.9847 - val_loss: 0.3078 - val_accuracy: 0.9000\n",
      "Epoch 19/100\n",
      "262/262 [==============================] - 0s 144us/step - loss: 0.0854 - accuracy: 0.9847 - val_loss: 0.3068 - val_accuracy: 0.8923\n",
      "Epoch 20/100\n",
      "262/262 [==============================] - 0s 128us/step - loss: 0.0779 - accuracy: 0.9847 - val_loss: 0.3067 - val_accuracy: 0.8923\n",
      "Epoch 21/100\n",
      "262/262 [==============================] - 0s 132us/step - loss: 0.0704 - accuracy: 0.9847 - val_loss: 0.3085 - val_accuracy: 0.8923\n",
      "Epoch 22/100\n",
      "262/262 [==============================] - 0s 135us/step - loss: 0.0640 - accuracy: 0.9885 - val_loss: 0.3101 - val_accuracy: 0.8923\n",
      "Epoch 23/100\n",
      "262/262 [==============================] - 0s 130us/step - loss: 0.0568 - accuracy: 0.9885 - val_loss: 0.3175 - val_accuracy: 0.8923\n",
      "Epoch 24/100\n",
      "262/262 [==============================] - 0s 140us/step - loss: 0.0530 - accuracy: 0.9924 - val_loss: 0.3249 - val_accuracy: 0.9000\n",
      "Epoch 25/100\n",
      "262/262 [==============================] - 0s 125us/step - loss: 0.0470 - accuracy: 0.9924 - val_loss: 0.3224 - val_accuracy: 0.8923\n",
      "Epoch 26/100\n",
      "262/262 [==============================] - 0s 137us/step - loss: 0.0440 - accuracy: 0.9885 - val_loss: 0.3317 - val_accuracy: 0.9000\n",
      "Epoch 27/100\n",
      "262/262 [==============================] - 0s 128us/step - loss: 0.0392 - accuracy: 0.9924 - val_loss: 0.3359 - val_accuracy: 0.9000\n",
      "Epoch 28/100\n",
      "262/262 [==============================] - 0s 131us/step - loss: 0.0359 - accuracy: 0.9924 - val_loss: 0.3398 - val_accuracy: 0.9077\n",
      "Epoch 29/100\n",
      "262/262 [==============================] - 0s 135us/step - loss: 0.0342 - accuracy: 0.9924 - val_loss: 0.3460 - val_accuracy: 0.9000\n",
      "Epoch 30/100\n",
      "262/262 [==============================] - 0s 141us/step - loss: 0.0298 - accuracy: 0.9924 - val_loss: 0.3478 - val_accuracy: 0.9000\n",
      "Epoch 31/100\n",
      "262/262 [==============================] - 0s 127us/step - loss: 0.0276 - accuracy: 0.9924 - val_loss: 0.3553 - val_accuracy: 0.9000\n",
      "Epoch 32/100\n",
      "262/262 [==============================] - 0s 139us/step - loss: 0.0255 - accuracy: 0.9924 - val_loss: 0.3589 - val_accuracy: 0.9000\n",
      "Epoch 33/100\n",
      "262/262 [==============================] - 0s 135us/step - loss: 0.0238 - accuracy: 0.9924 - val_loss: 0.3675 - val_accuracy: 0.9000\n",
      "Epoch 34/100\n",
      "262/262 [==============================] - 0s 140us/step - loss: 0.0216 - accuracy: 0.9924 - val_loss: 0.3676 - val_accuracy: 0.8923\n",
      "Epoch 35/100\n",
      "262/262 [==============================] - 0s 140us/step - loss: 0.0199 - accuracy: 0.9962 - val_loss: 0.3737 - val_accuracy: 0.9000\n",
      "Epoch 36/100\n",
      "262/262 [==============================] - 0s 129us/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.3775 - val_accuracy: 0.9000\n",
      "Epoch 37/100\n",
      "262/262 [==============================] - 0s 140us/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.3864 - val_accuracy: 0.9000\n",
      "Epoch 38/100\n",
      "262/262 [==============================] - 0s 117us/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.3915 - val_accuracy: 0.9000\n",
      "Epoch 39/100\n",
      "262/262 [==============================] - 0s 123us/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.3954 - val_accuracy: 0.9000\n",
      "Epoch 40/100\n",
      "262/262 [==============================] - 0s 123us/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.3991 - val_accuracy: 0.9000\n",
      "Epoch 41/100\n",
      "262/262 [==============================] - 0s 115us/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.4049 - val_accuracy: 0.9000\n",
      "Epoch 42/100\n",
      "262/262 [==============================] - 0s 113us/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.4092 - val_accuracy: 0.9000\n",
      "Epoch 43/100\n",
      "262/262 [==============================] - 0s 123us/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.4134 - val_accuracy: 0.9000\n",
      "Epoch 44/100\n",
      "262/262 [==============================] - 0s 130us/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.4181 - val_accuracy: 0.9000\n",
      "Epoch 45/100\n",
      "262/262 [==============================] - 0s 113us/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.4224 - val_accuracy: 0.9000\n",
      "Epoch 46/100\n",
      "262/262 [==============================] - 0s 121us/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.4279 - val_accuracy: 0.9000\n",
      "Epoch 47/100\n",
      "262/262 [==============================] - 0s 121us/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.4311 - val_accuracy: 0.9077\n",
      "Epoch 48/100\n",
      "262/262 [==============================] - 0s 119us/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.4342 - val_accuracy: 0.9000\n",
      "Epoch 49/100\n",
      "262/262 [==============================] - 0s 118us/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.4456 - val_accuracy: 0.9077\n",
      "Epoch 50/100\n",
      "262/262 [==============================] - 0s 119us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.4467 - val_accuracy: 0.9077\n",
      "Epoch 51/100\n",
      "262/262 [==============================] - 0s 118us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.4503 - val_accuracy: 0.9077\n",
      "Epoch 52/100\n",
      "262/262 [==============================] - 0s 121us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.4530 - val_accuracy: 0.9077\n",
      "Epoch 53/100\n",
      "262/262 [==============================] - 0s 118us/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.4584 - val_accuracy: 0.9077\n",
      "Epoch 54/100\n",
      "262/262 [==============================] - 0s 121us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.4629 - val_accuracy: 0.9077\n",
      "Epoch 55/100\n",
      "262/262 [==============================] - 0s 119us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.4672 - val_accuracy: 0.9077\n",
      "Epoch 56/100\n",
      "262/262 [==============================] - 0s 119us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.4705 - val_accuracy: 0.9077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "262/262 [==============================] - 0s 113us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.4745 - val_accuracy: 0.9077\n",
      "Epoch 58/100\n",
      "262/262 [==============================] - 0s 112us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.4777 - val_accuracy: 0.9077\n",
      "Epoch 59/100\n",
      "262/262 [==============================] - 0s 112us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.4805 - val_accuracy: 0.9077\n",
      "Epoch 60/100\n",
      "262/262 [==============================] - 0s 115us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.4851 - val_accuracy: 0.9077\n",
      "Epoch 61/100\n",
      "262/262 [==============================] - 0s 117us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.4879 - val_accuracy: 0.9077\n",
      "Epoch 62/100\n",
      "262/262 [==============================] - 0s 114us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.4917 - val_accuracy: 0.9077\n",
      "Epoch 63/100\n",
      "262/262 [==============================] - 0s 111us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.9077\n",
      "Epoch 64/100\n",
      "262/262 [==============================] - 0s 108us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.4965 - val_accuracy: 0.9077\n",
      "Epoch 65/100\n",
      "262/262 [==============================] - 0s 117us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.4966 - val_accuracy: 0.9077\n",
      "Epoch 66/100\n",
      "262/262 [==============================] - 0s 118us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.5014 - val_accuracy: 0.9077\n",
      "Epoch 67/100\n",
      "262/262 [==============================] - 0s 119us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5053 - val_accuracy: 0.9077\n",
      "Epoch 68/100\n",
      "262/262 [==============================] - 0s 119us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.5098 - val_accuracy: 0.9077\n",
      "Epoch 69/100\n",
      "262/262 [==============================] - 0s 120us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5131 - val_accuracy: 0.9077\n",
      "Epoch 70/100\n",
      "262/262 [==============================] - 0s 114us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5151 - val_accuracy: 0.9077\n",
      "Epoch 71/100\n",
      "262/262 [==============================] - 0s 113us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5207 - val_accuracy: 0.9077\n",
      "Epoch 72/100\n",
      "262/262 [==============================] - 0s 112us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5212 - val_accuracy: 0.9077\n",
      "Epoch 73/100\n",
      "262/262 [==============================] - 0s 111us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5240 - val_accuracy: 0.9077\n",
      "Epoch 74/100\n",
      "262/262 [==============================] - 0s 115us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5280 - val_accuracy: 0.9077\n",
      "Epoch 75/100\n",
      "262/262 [==============================] - 0s 114us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5318 - val_accuracy: 0.9077\n",
      "Epoch 76/100\n",
      "262/262 [==============================] - 0s 113us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5360 - val_accuracy: 0.9077\n",
      "Epoch 77/100\n",
      "262/262 [==============================] - 0s 123us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5374 - val_accuracy: 0.9154\n",
      "Epoch 78/100\n",
      "262/262 [==============================] - 0s 124us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5406 - val_accuracy: 0.9154\n",
      "Epoch 79/100\n",
      "262/262 [==============================] - 0s 119us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5425 - val_accuracy: 0.9154\n",
      "Epoch 80/100\n",
      "262/262 [==============================] - 0s 117us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5458 - val_accuracy: 0.9154\n",
      "Epoch 81/100\n",
      "262/262 [==============================] - 0s 121us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5486 - val_accuracy: 0.9154\n",
      "Epoch 82/100\n",
      "262/262 [==============================] - 0s 117us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5513 - val_accuracy: 0.9154\n",
      "Epoch 83/100\n",
      "262/262 [==============================] - 0s 113us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5548 - val_accuracy: 0.9154\n",
      "Epoch 84/100\n",
      "262/262 [==============================] - 0s 113us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5583 - val_accuracy: 0.9231\n",
      "Epoch 85/100\n",
      "262/262 [==============================] - 0s 110us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5612 - val_accuracy: 0.9231\n",
      "Epoch 86/100\n",
      "262/262 [==============================] - 0s 119us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5623 - val_accuracy: 0.9154\n",
      "Epoch 87/100\n",
      "262/262 [==============================] - 0s 116us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5652 - val_accuracy: 0.9231\n",
      "Epoch 88/100\n",
      "262/262 [==============================] - 0s 117us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5662 - val_accuracy: 0.9154\n",
      "Epoch 89/100\n",
      "262/262 [==============================] - 0s 118us/step - loss: 9.9746e-04 - accuracy: 1.0000 - val_loss: 0.5705 - val_accuracy: 0.9231\n",
      "Epoch 90/100\n",
      "262/262 [==============================] - 0s 121us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5732 - val_accuracy: 0.9154\n",
      "Epoch 91/100\n",
      "262/262 [==============================] - 0s 112us/step - loss: 9.7006e-04 - accuracy: 1.0000 - val_loss: 0.5780 - val_accuracy: 0.9231\n",
      "Epoch 92/100\n",
      "262/262 [==============================] - 0s 113us/step - loss: 9.0765e-04 - accuracy: 1.0000 - val_loss: 0.5799 - val_accuracy: 0.9231\n",
      "Epoch 93/100\n",
      "262/262 [==============================] - 0s 111us/step - loss: 8.6112e-04 - accuracy: 1.0000 - val_loss: 0.5814 - val_accuracy: 0.9231\n",
      "Epoch 94/100\n",
      "262/262 [==============================] - 0s 113us/step - loss: 8.2805e-04 - accuracy: 1.0000 - val_loss: 0.5842 - val_accuracy: 0.9231\n",
      "Epoch 95/100\n",
      "262/262 [==============================] - 0s 118us/step - loss: 7.9675e-04 - accuracy: 1.0000 - val_loss: 0.5866 - val_accuracy: 0.9231\n",
      "Epoch 96/100\n",
      "262/262 [==============================] - 0s 119us/step - loss: 7.7040e-04 - accuracy: 1.0000 - val_loss: 0.5884 - val_accuracy: 0.9231\n",
      "Epoch 97/100\n",
      "262/262 [==============================] - 0s 115us/step - loss: 7.4744e-04 - accuracy: 1.0000 - val_loss: 0.5900 - val_accuracy: 0.9231\n",
      "Epoch 98/100\n",
      "262/262 [==============================] - 0s 118us/step - loss: 7.2328e-04 - accuracy: 1.0000 - val_loss: 0.5913 - val_accuracy: 0.9231\n",
      "Epoch 99/100\n",
      "262/262 [==============================] - 0s 115us/step - loss: 6.9609e-04 - accuracy: 1.0000 - val_loss: 0.5936 - val_accuracy: 0.9231\n",
      "Epoch 100/100\n",
      "262/262 [==============================] - 0s 114us/step - loss: 6.7947e-04 - accuracy: 1.0000 - val_loss: 0.5952 - val_accuracy: 0.9231\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, batch_size = 10, validation_split = 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194/194 [==============================] - 0s 23us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.526478635315086, 0.9432989954948425]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (model.predict(X_test)).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9432989690721649"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "392/392 [==============================] - 0s 36us/step - loss: 0.1894 - accuracy: 0.9745\n"
     ]
    }
   ],
   "source": [
    "### experiment\n",
    "import dill\n",
    "pipe = make_pipeline(mapper, model)\n",
    "pipe.fit(X_train, y_train)\n",
    "pipe.predict(X_test).round()\n",
    "dill.dump(pipe, open('pipe.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
